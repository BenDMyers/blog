---
title: "The Accessibility Tree"
date: 2019-11-02
description: Understanding the flow of page contents from browser to screenreader caused me to radically rethink accessible markup.
cover: 'https://i.imgur.com/tdz9zBE.png'
coveralt: A pattern of pink-and-yellow pointer cursors on a blue background.
emoji: ðŸ§±
tags: ["web accessibility", "accessibility", "web development", "accessibility tree"]
---

<TOC includeFootnotes="true" />

<!-- REWORK INTRODUCTION -->

How do screenreaders work?

If you're a web developer, your first answer might be pretty similar to mine: "Surely they read the DOM... right?" But this hesitant, web-centric answer doesn't help a whole lot with the follow-up question: how do screenreaders read programs that aren't browsers?

It's easy to take it for granted that screenreaders can access page contents from a browser. They just seem to work, more or less. However, understanding the flow of page contents from browser to screenreader caused me to radically rethink accessible markup.

Let's dive into how browsers and operating systems work together 

## Screenreaders of Yore

The earliest screenreaders were built for text-only, DOS operating systems, and they had a lot of their work cut out for them. The text was all there in the device's screen buffer, so screenreaders just needed to send the buffer's contents to speech synthesis hardware and call it a day.<Fn fn="1" />

Graphical user interfaces proved trickier for screenreaders, however, since GUIs don't have any intrinsic text representations. Instead, screenreaders like Berkeley Systems' outSPOKEN had to resort to intercepting low-level graphics instructions sent to the device's graphics engine.<Fn fn="2" /> Screenreaders then attempted to interpret these instructions. This rectangle with some text inside is probably a button. That text over there is highlighted, so it's probably selected. These assumptions about what's on the screen were then stored in the screenreader's own database, called an <dfn>off-screen model</dfn>.

<WideImage
    src="/outSPOKEN.jpg"
    alt="outSPOKEN menu"
    caption={
        <>
            Screenshot courtesy of <a href="https://www.macintoshrepository.org/2080-outspoken-1-7">Macintosh Repository</a>
        </>
    }
/>

Off-screen models posed many problems. Accounting for the alignment and placement of UI elements was tricky, and errors in calculations could snowball into bigger errors. The heuristics that off-screen models relied on could be flimsy â€” assuming they've even been implemented for the UI elements you want in the first place!<Fn fn="3" />

Guessing at what graphics instructions mean is clearly messy, but could something like an off-screen model work for webpages? Could screenreaders scrape HTML or traverse the DOM, and insert the page contents into the model?

Screenreaders such as JAWS tried this approach, but it, too, had its problems. Screenreaders and other assistive technologies usually strive to be general purpose and work no matter which application the user is running, but that's hampered by including a lot of web-parsing logic. Also, it left users high and dry whenever new HTML elements were introduced. For instance, when sites started using HTML5's new tags such as `<header>` and `<footer>`, JAWS omitted key page contents until an (expensive) update could be pushed out.<Fn fn="4" />

## Back to the Drawing Board

Assistive technologies that build their own off-screen models of webpages or applications can be error-prone and susceptible to new, unfamiliar elements and controls. These issues are symptoms of a bigger problem with the approach: trying to reverse engineer meaning is like swimming upstream.

Instead of having assistive technologies make guesses about screen contents, let's have applications tell assistive technologies exactly what they're trying to convey.

## Accessibility APIs and Building Blocks

If you want applications such as browsers to be able to expose information to assistive technologies, you'll need them to speak the same language.

## From the DOM to the Accessibility Tree

<Lorem />

## But Why Do We Care?

Why should web developers care about the accessibility tree? Is it any more than just some interesting trivia about browser internals?

Understanding the flow of a webpage's contents from browser to assistive technology changed the way I view the web apps I work on. I think there are three key ways that this flow impacts web developers:

1. It explains discrepancies between different assistive technologies on different platforms.
2. Browsers can use accessibility trees to optimize how pages are exposed to assistive technologies.
3. Web developers have a responsibility to be good stewards of the accessibility tree.

### Explaining Discrepancies

We know that there are three key players in the flow of web contents to assistive technologies: the browser, the operating system accessibility API, and the assistive technology itself. This gives us three possible places to introduce discrepancies:

- Operating system accessibility APIs could provide different building blocks.
- Browsers could use assemble their accessibility trees differently.
- Assistive technologies could interpret those building blocks in different ways.



### Browser Optimizations

<Lorem />

### Tree Stewardship

Being aware of the accessibility tree and how it impacts your users' experience should make one thing clear: to build quality web applications, we must be responsible stewards of our applications' accessibility trees. Fortunately, we have two tools at our disposal: semantic markup and ARIA.

When we use semantic markup, we make it much, much easier for browsers to use the most appropriate building blocks. When we use an `<input type="checkbox" />` element, for instance, the browser knows it can put a `Checkbox` object in the tree with all of the properties that that entails, and it can trust that that's an accurate representation of the UI element.

***

<FootnotesContainer>
    <Footnote fn="1">
        Yes, this <em>is</em> an oversimplification.
    </Footnote>
    <Footnote fn="2" author="Rich Schwerdtfeger" publication="BYTE" title="Making the GUI Talk" url="https://developer.paciellogroup.com/blog/2015/01/making-the-gui-talk-1991-by-rich-schwerdtfeger/" />
    <Footnote fn="3" author="LÃ©onie Watson & Chaals McCathie Nevile" publication="Smashing Magazine" title="Accessibility APIs: A Key To Web Accessibility" url="https://www.smashingmagazine.com/2015/03/web-accessibility-with-accessibility-api/" />
    <Footnote fn="4" author="Marco Zehe" title="Why accessibility APIs matter" url="https://marcozehe.wordpress.com/2013/09/07/why-accessibility-apis-matter/" />
</FootnotesContainer>