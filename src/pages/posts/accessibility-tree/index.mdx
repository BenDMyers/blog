---
title: "The Accessibility Tree"
date: 2019-11-03
description: Understanding the flow of page contents from browser to screenreader caused me to radically rethink accessible markup.
cover: 'https://i.imgur.com/tdz9zBE.png'
coveralt: A pattern of pink-and-yellow pointer cursors on a blue background.
emoji: ðŸ§±
tags: ["web accessibility", "accessibility", "web development", "accessibility tree"]
---

<TOC includeFootnotes="true" />

<!-- REWORK INTRODUCTION -->

How do screenreaders work?

If you're a web developer, your first answer might be pretty similar to mine: "Surely they read the DOM... right?" But this hesitant, web-centric answer doesn't help a whole lot with the follow-up question: how do screenreaders read programs that aren't browsers?

It's easy to take it for granted that screenreaders can access page contents from a browser. They just seem to work, more or less. However, understanding the flow of page contents from browser to screenreader caused me to radically rethink accessible markup.

Let's dive into how browsers and operating systems work together 

## Screenreaders of Yore

The earliest screenreaders were built for text-only, DOS operating systems, and they had a lot of their work cut out for them. The text was all there in the device's screen buffer, so screenreaders just needed to send the buffer's contents to speech synthesis hardware and call it a day.<Fn fn="1" />

Graphical user interfaces proved trickier for screenreaders, however, since GUIs don't have any intrinsic text representations. Instead, screenreaders like Berkeley Systems' outSPOKEN had to resort to intercepting low-level graphics instructions sent to the device's graphics engine.<Fn fn="2" /> Screenreaders then attempted to interpret these instructions. This rectangle with some text inside is probably a button. That text over there is highlighted, so it's probably selected. These assumptions about what's on the screen were then stored in the screenreader's own database, called an <dfn>off-screen model</dfn>.

<WideImage
    src="/outSPOKEN.jpg"
    alt="outSPOKEN menu"
    caption={
        <>
            Screenshot courtesy of <a href="https://www.macintoshrepository.org/2080-outspoken-1-7">Macintosh Repository</a>
        </>
    }
/>

Off-screen models posed many problems. Accounting for the alignment and placement of UI elements was tricky, and errors in calculations could snowball into bigger errors. The heuristics that off-screen models relied on could be flimsy â€” assuming they've even been implemented for the UI elements you want in the first place!<Fn fn="3" />

Guessing at what graphics instructions mean is clearly messy, but could something like an off-screen model work for webpages? Could screenreaders scrape HTML or traverse the DOM, and insert the page contents into the model?

Screenreaders such as JAWS tried this approach, but it, too, had its problems. Screenreaders and other assistive technologies usually strive to be general purpose and work no matter which application the user is running, but that's hampered by including a lot of web-parsing logic. Also, it left users high and dry whenever new HTML elements were introduced. For instance, when sites started using HTML5's new tags such as `<header>` and `<footer>`, JAWS omitted key page contents until an (expensive) update could be pushed out.<Fn fn="4" />

## Back to the Drawing Board

Assistive technologies that build their own off-screen models of webpages or applications can be error-prone and susceptible to new, unfamiliar elements and controls. These issues are symptoms of a bigger problem with the approach: trying to reverse engineer meaning is like swimming upstream.

Instead of having assistive technologies make guesses about screen contents, let's have applications tell assistive technologies exactly what they're trying to convey.

## Accessibility APIs and Building Blocks

If you want applications such as browsers to be able to expose information to assistive technologies, you'll need them to speak the same language. Since no developer wants to have to support exposing their application's contents to JAWS and NVDA and VoiceOver and Dragon NaturallySpeaking and every other assistive technology individually, we'll need assistive technologies to share a common language. That way, those who are developing browsers or other applications need only expose their contents once and any assistive technology can use it.

This <i>lingua franca</i> is provided by the user's operating system. Specifically, operating systems have interfacesâ€”<dfn>accessibility APIs</dfn>â€”that help translate between programs and assistive technologies. These accessibility APIs have sexy, exciting names such as Microsoft Active Accessibility, IAccessible2, andâ€”creativelyâ€”Apple Accessibility API.


How do these accessibility APIs help? They give programs the building blocks they need to describe their contents, and they serve as a convenient middleman between a program and an assistive technology.

### Building Blocks

These building blocks are data structures called <dfn>accessible objects</dfn>. They're bundles of properties that represent the functionality of a UI element, without any of the presentational or aesthetic information.

One of these building blocks could be a `Checkbox` object, for instance.

<!-- CHECKBOX ACCESSIBLE OBJECT DIAGRAM -->

You could also have a `Button` object:

<!-- BUTTON ACCESSIBLE OBJECT DIAGRAM -->

These building blocks enable all applications to describe themselves in a similar way. As a result, a checkbox is a checkbox, as far as assistive technology is concerned, regardless of whether it appears in a Microsoft Word dialog box or on a web form.

<!-- DIALOG/FORM DIAGRAM -->

These building blocks, by the way, contain three kinds of information about a UI element:

* **Role:** What kind of element is this? Is it text, a button, a checkbox, or something else? This information matters because it lays out expectations for what this element is doing here, how to interact with this element, and what will happen if you do interact with it.

* **Label:** An identifier, called an <dfn>accessible name</dfn>, for this element. Buttons will generally use their text contents to determine their name, so `<button>Submit</button>` will have the name "Submit." HTML form fields often get their name from associated `<label>` elements. Names are used by screenreaders to announce an element, and speech recognition users can use names in their voice commands to target specific elements.

* **State and other properties:** Other functional aspects of an element that would be relevant for a user or an assistive technology to be aware of. Is this checkbox checked or unchecked? Is this expandable section currently hidden? Will clicking this button open a dropdown menu? These properties tend to be much more subject to change than an element's role or name.

You can see all three of these in just about any screenreader announcement:

<!-- VOICEOVER SCREENSHOT -->

### Accessibility APIs As a Middleman

When an application has described its contents using these building blocks, it then sends this new representation to the accessibility APIs. Assistive technology polls the accessibility APIs regularly. They get information such as the active window, programs' contents, and the currently focused element. 

They can use this information in different ways. Screenreaders use this information to decide what to announce, or to enable shortcuts that allow the user to jump between different elements of the same type. Speech recognition software uses this information to determine which elements the user can target with their voice commands and how. Screen magnifiers use this information to judge where the user's cursor is, in case they need to focus elsewhere.

This middleman relationship works both ways. Accessibility APIs enable assistive technologies to interact with programs, giving their users more flexibility. For instance, eye-tracking technology can interpret a user's gaze dwelling on an element as a click, and send that event back through the accessibility API so that the browser treats it the same as a mouse click.

## From the DOM to the Accessibility Tree

<Lorem />

## But Why Do We Care?

Why should web developers care about the accessibility tree? Is it any more than just some interesting trivia about browser internals?

Understanding the flow of a webpage's contents from browser to assistive technology changed the way I view the web apps I work on. I think there are three key ways that this flow impacts web developers:

1. It explains discrepancies between different assistive technologies on different platforms.
2. Browsers can use accessibility trees to optimize how pages are exposed to assistive technologies.
3. Web developers have a responsibility to be good stewards of the accessibility tree.

### Explaining Discrepancies

We know that there are three key players in the flow of web contents to assistive technologies: the browser, the operating system accessibility API, and the assistive technology itself. This gives us three possible places to introduce discrepancies:

- Operating system accessibility APIs could provide different building blocks.
- Browsers could use assemble their accessibility trees differently.
- Assistive technologies could interpret those building blocks in different ways.

These differences are, honestly, minute most of the time. However, bugs that affect certain combinations of browsers and assistive technologies are prevalent enough that you should be testing your sites on many different combinations.

### Browser Optimizations

When constructing accessibility trees, many browsers employ heuristics to improve the user experience. For instance, many developers use the CSS rules `display: none;` or `visibility: hidden;` to remove content from the page. However, since the content is still in the HTML, those using assistive technologies would still be able to get to it, which could have undesirable consequences. Browsers instead use these CSS rules as flags that they should remove those elements from the accessibility tree, too. This is why we have to resort to [other tricks to create screenreader-only text](https://cloudfour.com/thinks/see-no-evil-hidden-content-and-accessibility/#showing-additional-content-for-screen-readers).

Browsers use other tricks to protect users from developers' bad habits. For instance, to counter the [problem of layout tables](https://webaim.org/techniques/tables/), the source code for both Google Chrome<Fn fn="***" /> and Mozilla Firefox<Fn fn="***" /> will guess at whether a `<table>` element is being used for layout or for tabular data and adjust the accessibility tree accordingly.

### Tree Stewardship

Being aware of the accessibility tree and how it impacts your users' experience should make one thing clear: to build quality web applications, we must be responsible stewards of our applications' accessibility trees. Fortunately, we have two tools at our disposal: semantic markup and ARIA.

When we use semantic markup, we make it much, much easier for browsers to use the most appropriate building blocks. When we use `<input type="checkbox" />`, for instance, the browser knows it can put a `Checkbox` object in the tree with all of the properties that that entails, and it can trust that that's an accurate representation of the UI element.

Semantic markup will work for the majority of our needs, but there are times when we need to make tweaks here and there to our application's accessibility tree. This is what ARIA is for! In my next post, I'll explore how ARIA entirely serves to modify elements' representation in the accessibility tree.

***

<FootnotesContainer>
    <Footnote fn="1">
        Yes, this <em>is</em> an oversimplification.
    </Footnote>
    <Footnote fn="2" author="Rich Schwerdtfeger" publication="BYTE" title="Making the GUI Talk" url="https://developer.paciellogroup.com/blog/2015/01/making-the-gui-talk-1991-by-rich-schwerdtfeger/" />
    <Footnote fn="3" author="LÃ©onie Watson & Chaals McCathie Nevile" publication="Smashing Magazine" title="Accessibility APIs: A Key To Web Accessibility" url="https://www.smashingmagazine.com/2015/03/web-accessibility-with-accessibility-api/" />
    <Footnote fn="4" author="Marco Zehe" title="Why accessibility APIs matter" url="https://marcozehe.wordpress.com/2013/09/07/why-accessibility-apis-matter/" />
    <Footnote fn="***">
        <a href="https://chromium.googlesource.com/chromium/blink/+/master/Source/modules/accessibility/AXTable.cpp">Chromium source code</a>
    </Footnote>
    <Footnote fn="***">
        <a href="https://dxr.mozilla.org/mozilla-central/source/accessible/generic/TableAccessible.cpp">Firefox source code</a>
    </Footnote>
</FootnotesContainer>